# 《智能时代》的原文摘录

全书对大数据和智能革命带来的思维革命、技术上的挑战。以及机器智能如何改变人类社会，都作出了全面的讲解
“用不确定的眼光看待世界，再用信息来消除这种不确定性”。这是大数据解决智能问题的本质。
本书的一个重要观点是：机器智能革命的发生来自大数据量的积累达到质变的奇点。从这个角度来看，机器的学习同人类的学习并没有什么本质的不同。

计算机之所以能够战胜人类，是因为机器获得智能的方式与人类不同，它不是靠逻辑推理，而是靠大数据和智能算法。

机器不会控制人类，但是制造智能机器的人可以

科学研究发展的四个范式,即描述自然现象的实验科学、以牛顿定律和麦克斯韦方程等为代表的理论科学、模拟复杂现象的计算科学和今天的数据密集型科学
吴军博士在书中提到了世界的不确定性来自两个方面，一是影响世界的变量太多以至于无法用数学模型来描述;二是来自客观世界本身:不确定性是我们所在宇宙的特性。
解决智能问题，就是将问题转化为消除不确定性的问题，大数据则是解决不确定性问题的良药。
即每一次技术革命都会围绕着一个核心技术展开，第一次工业革命是蒸汽机，第二次工业革命是电，信息革命是计算机和半导体芯片，当下的智能革命则是大数据和机器智能。
未来的社会，属于那些具有创意的人，包括计算机科学家，而不属于掌握某种技能做重复性工作的人。
其实只要数据量足够，就可以用若干个简单的模型取代一个复杂的模型。这种方法被称为数据驱动方法，因为它是先有大量的数据，而不是预设的模型，然后用很多简单的模型去契合数据（Fit Data)。
在有大数据之前，计算机并不擅长于解决需要人类智能的问题，但是今天这些问题换个思路就可以解决了，其核心就是变智能问题为数据问题。
一些数据专家将大数据的特征概括成三个V，即大量（Vast)、多样性（Variety)和及时性（Velocity)，这种说法虽然方便记忆，但并不全面准确。
并非所有大数据所必需的特征，一些数据没有及时性，一样可以被称为大数据。
今后把Variety解释成多维度。
大数据的第三个重要特征，也是人们常常忽视的，就是它的全面性，或者说完备性
仔细推敲英语中big data这种说法，我们不得不承认这个提法非常准确，它最重要的是传递了一种信息——大数据是一种思维方式的改变。
其核心就是变智能问题为数据问题。
思维的革命在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因...

序一 大数据与机器智能催生智能时代

前言 人类的胜利

第一章 数据——人类建造文明的基石

第二章 大数据和机器智能

第三章 思维的革命

第四章 大数据与商业

第五章 大数据和智能革命的技术挑战

第六章 未来智能化产业

第七章 智能革命和未来社会

相比国际象棋，围棋的人搜索空间要大很多，AlphaGo的计算能力相比深蓝，骑士并没有这么多倍的提高，他靠的是好的搜索算法，能够准确地聚焦搜索空间，因此能够在很短的时间里算出最佳行棋步骤。——前言
AlphaGo无论是在训练模型时，还是在下棋时所采用的算法都是几十年前大家就已经知道的机器学习和博弈树搜索算法，Google所做的工作时让这些算法能够在上万台甚至上百万台服务器上并行运行，这就使得计算机解决职能问题的能力有了本质的人提高。
机器不会控制人类，但是制造智能机器的人可以。而科技在人类进步中总是扮演着最活跃最革命的角色，它的发展时无法阻止的，我们能做的人就是面对现实，抓住只能革命的机遇，而不是回避它、否定它和阻止它。未来的社会，属于那些具有创意的人，包括计算机科学家，而不属于掌握某种技能做重复性工作的人。
各种数学模型的基础都离不开概率论和统计学。
切比雪夫不等式，当样本数足够多时，一个随机变量（比如观察到的各个年龄段观众的比例）和他的数学期望值（比如真实情况下所有看电影的观众中不同年龄段的比例）之间的误差可以任意小。回到数学模型上，其实只要数据量足够，就可以用若干个简单的模型取代一个复杂的模型。这种方法被称为数据驱动方法，因为它时现有大量的数据，而不是预设的模型，然后用很多简单的模型去契合数据(Fit Data)。
在今天IT领域中，越来越多的问题可以用数据驱动方法来解决。具体讲，就是当我们对一个问题暂时不能用简单而准确的方法解决时，我们可以根据以往的历史数据，构造很多近似的模型来逼近真实情况，这实际上使用计算量和数据量来换取研究的时间。这种方法不仅仅是经验论，他在数学上是有严格保障的。
机器智能最重要的是能够解决人脑所能解决的问题，而不在于是否需要采用和人一样的方法。如今在很多与“智能”有关的研究领域，比如图像识别和自然语言理解，如果所采用的方法无法利用数据量的优势，...

如果我们把资本和机械动能作为大航海时代以来全球近代化的推动力的话，那么数据将成为下一次技术革命和社会革命的核心动力
如何处理数据，过滤掉没有用的噪音和有害的数据，从而获取数据背后的信息，就成为技术甚至是一种艺术。只有善用数据，我们才能够得到意想不到的惊喜，即数据背后的信息。

数据和所想获得的信息之间的联系通常是间接的，它要通过不同数据之间的相关性才能体现出来。可以说，相关性是让数据发挥作用的魔棒。

在工程上，采用多而简单的模型常常比一个精确的模型成本更低，也被更使用得更普遍

数据是文明的基石，人类对它的认识也反映了文明的程度

在今天，谈论数据时，人们常常把它和信息的概念混同起来，然而严格地讲，数据和信息虽然有相通之处，但还是不同的。 
信息是关于世界、人和事的描述，它比数据来得抽象。信息既可以是我们人类创造的，也可以是天然存在的客观事实。信息有时藏在事物的背后，需要挖掘和测量才能得到。
不过，数据和信息还是稍有不同，虽然它最大的作用在于承载信息，但是并非所有的数据都承载了有意义的信息。数据本身是人造物，因此它们可以被随意制造，甚至可以被伪造。没有信息的数据通常没有太大意义，人们也不太关心。那些有用的数据、毫无意义的数据和伪造的数据常常是混在一起的，后面两种数据无疑会干扰我们从数据中获取有用的信息，因此如何处理数据，过滤掉没有用的噪声和删除有害的数据，从而获取数据背后的信息，就成为技术甚至是一种艺术。只有善用数据，我们才能够得到意想不到的惊喜，即数据背后的信息。

早期人类得到的数据是从哪里来的？其中一个重要的来源是对现象的观察。从观察中总结出数据，是人类和动物的重要区别，后者虽具有观察能力，却无法总结出数据，但是人类有这个能力。而得到数据和使用数据的能力，是衡量文明发展水平的标准之一。我们的文明从一开始就伴随着对数据的使用，可以说数据是文明的基石。

早期人类得到的数据是从哪里来的？其中一个重要的来源是对现象的观察。从观察中总结出数据，是人类和动物的重要区别，后者虽具有观察能力，却无法总结出数据，但是人类有这个能力。 而得到数据和使用数据的能力，是衡量文明发展水平的标准之一。

具体到下棋的策略，AlphaGo里面有两个关键的技术。第一个关键技术是把棋盘上当前的状态变成一个获胜概率的数学模型，这个模型里面没有任何人工的规则，而是安全靠前面所说的数据训练出来的。第二个关键技术是启发式搜索算法——蒙特卡罗树搜索算法（Monte Carlo Tree Search）,它能将搜索的空间限制在非常有限的范围内，保证计算机能够快速找到好的下法。

20世纪70年代，中国的国际交往开始恢复正常，为了加快中国的建设，中国政府决定向其他国家就一些重大建设项目进行招标，其中一项是大庆油田石油设备。当时大庆油田的情况中国政府对外保密，西方国家了解甚少，甚至连它的具体地点都不知道。但是来自日本的投标却非常有针对性并且一举中标。其背后的原因是，日本人通过1964年中国的《人民画报》上刊登的铁人王进喜的照片，分析出了关于大庆油田的许多细节信息。

很多时候，我们无法直接获得信息（比如疫情传播情况），但是我们可以将相关联的信息（比如各地搜索情况）量化，然后通过数学模型，间接地得到所要的信息。而各种数学模型的基础都离不开概率论和统计学。

越想要得到准确的统计结果，需要的统计数据量就越大。在上面的例子中，统计的样本总数是1678人，要得出大致结论是足够了， 但是如果我们一定要说"41岁及以上的观众就是 29.2%"，或者"15岁及以下的观众一定超过20%"那样非常确定的话，大家就可能会挑战这个结论了，因为统计是有随机性的，也是有误差的，仅仅上千人的数据得不到这样准确的结论。 
统计除了要求数据量必须充分以外，还要求采样的数据具有代表性。有些时候不是数据量足够大，统计结果就一定淮确。统计所使用的数据必须和我们想统计的目标相一致。为了说明这点，让我们来看一个大量统计却没有得到准确估计的案例。

以前：要建立数学模型就要解决两个问题，首先是采用什么样的模型，其次是模型的参数是多少。

要建立数学模型就要解决两个问题，首先是采用什么样的模型，其次是模型的参数是多少。
    模型的选择不是一件容易的事情，通常简单的模型未必和真    实情况相匹配，一个典型的例子就是，无论支持地心说的托勒密，还是提出日心说的哥白尼，都假定行星运动轨迹的基本模型是最简单的圆，而不是更准确的椭圆。由此可见，如果一开始模型选得不好，那么以后修修补补就很困难。因此，在过去，无论在理论上还是工程上，大家都把主要的精力放在寻找模型上。
    有了模型之后，第二步就是要找到模型的参数，以便让模型至少和以前观察到的数据相吻合。这一点在过去的被重视程度远不如找模型。但是今天它又有了一个比较时髦而高深的词一一机器学习。

鉴于完美的模型未必存在，即使存在，找到它也非常不容易而且费时间，因此就有人考虑是否能通过用很多简单不完美的模型凑在一起，起到完美模型的效果呢?比如说，是否可以通过很多很多圆互相嵌套在一起，建立一个地心说模型，和牛顿推演出的日心说模型一样准确呢?如今这个答案是肯定的，从理论上讲，只要找到足够多的具有代表性的样本(数据)，就可以运用数学找到个模型或者一组模型的组合，使得它和真实情况非常接近。

回到数学模型上，其实只要数据量足够，就可以用若干个简单的模型取代一个复杂的模型。这种方法被称为数据驱动方法，因为它是先有大量的数据，而不是预设的模型，然后用很多简单的模型去契合数据（Fit Data）。

回到数学模型上，其实只要数据量足够，就可以用若干个简单的模型取代一个复杂的模型。这种方法被称为数据驱动方法，因为它是先有大量的数据，而不是预设的模型，然后用很多简单的模型去契合数据（Fit Data)。虽然这种数据驱动方法在数据量不足时找到的一组模型可能和真实的模型存在一定的偏差，但是在误差允许的范围内，单从结果上看和精确的模型是等效的，这在数学上是有根据的。从原理上讲，这类似于前面提到的切比雪夫大数定律。 
当然，数据驱动方法要想成功，除了数据量大之外，还要有一个前提，那就是样本必须非常具有代表性，这在任何统计学教科书里就是一句话，但是在现实生活中要做到是非常难的。

回到数学模型上，其实只要数据量足够，就可以用若干个简单的模型取代一个复杂的模型。这种方法被称为数据驱动方法，因为它是先有大量的数据，而不是预设的模型，然后用很多简单的模型去契合数据（Fit Data）。虽然这种数据驱动方法在数据量不足时找到的一组模型可能和真实的模型存在一定的偏差，但是在误差允许的范围内，单从结果上看和精确的模型是等效的，这在数学上是有根据的。
……
当然，数据驱动方法要想成功，除了数据量大之外，还要有一个前提，那就是样本必须非常具有代表性，这在任何统计学教科书里就是一句话，但是在现实生活中要做到是非常难的。
……
数据驱动方法最大的优势在于，它可以在最大程度上得益于计算机技术的进步。

在今天的IT领域中，越来越多的问题可以用数据驱动方法来解决。具体讲，就是当我们对一个问题暂时不能用简单而准确的方法解决时，我们可以根据以往的历史数据，构造很多近似的模型来逼近真实情况，这实际上是用计算量和数据量来换取研究的时间。这种方法不仅仅是经验论，它在数学上是有严格保障的。

如果我们把资本和机械动能作为大航海时代以来全球近代化的推动力，那么数据将成为下一代技术革命和社会变革的核心动力。

信息是关于世界、人和事的描述，它比数据来得抽象。

知识比信息更高一个层次，也更加抽象，它具有系统性的特征。比如通过测量星球的位置和对应的时间，就得到数据；通过这些数据得到星球运动的轨迹，就是信息；通过信息总结出开普勒三定律，就是知识。人类的进步就是靠使用知识不断地改变我们的生活和周围的世界，而数据是知识的基础。

很多时候，我们无法直接获得信息（比如疫情传播请），但是我们可以将相关联的信息（比如各地搜索情况）量化，然后通过数学模型，间接地得到所要的信息。而各种数学模型的基础都离不开概率论和统计学。

统计学，有时又被称为数理统计，是建立在概率论基础之上，收集、处理和分析数据，找到数据内在的关联性和规律性的学科。

回到数学模型上，只要数据量足够，就可用若干个简单的模型取代一个复杂的模型，这种方法被称为数据驱动方法。

大量数据的使用，最大的意义在于它能让计算机完成一些过去只有人类才能做的事情，这最终将带来一场智能革命。

让一台机器和一个人坐在幕后，让一个裁判同时与幕后的人和机器进行交流，如果这个裁判无法判断自己交流的对象是人还是机器，这就说明这台机器有了和人同等的智能。这种方法被后人称为图灵测试。

机器智能最重要的是能够解决人脑所能解决的问题，而不在于是否需要采用和人一样的方法。

到了20世纪70年代，人类开始尝试机器智能的另一条发展道路，即采用数据驱动和超级计算的方法。

</数据驱动的方法从20世纪70年代开始起步，在八九十年代得到缓慢但稳步的发展。进入21世纪后，由于互联网的出现，使得可用的数据量剧增，数据驱动方法的优势越来越明显，最终完成了从量变到质变的飞跃。如今很多需要类似人类智能才能做到的事情，计算机已经可以胜任了，这得益于数据量的增加。
全世界各个领域数据不断的向外扩展，渐渐形成了另外一个特点，那就是很多数据开始出现交叉，各个维度的数据从点和线渐渐连成了网，或者说，数据之间的关联性极大地增强，在这样的背景下，就出现了大数据。

大数据是一种思维方式的转变。在有大数据之前，计算机并不擅长解决需要人类智能来解决的问题，但是今天这些问题换个思路就可以解决了，其核心就是变智能问题为数据问题。当数据量足够大以后，很多智能问题就可以转化为数据处理的问题了。
我们对大数据的认识不应该只停留在统计、改进产品和销售，或者提供决策的支持上，而应该看到它（和摩尔定律、数学模型一起）导致了机器智能的产生。

让一个机器和一个人坐在幕后，让一个裁判同时与幕后的人和机器进行交流，如果这个裁判无法判断自己交流的对象是人还是机器，就说明这台及其有了和人同等的智能。这种方法被后人称为图灵测试（Turing Test).

人工智能这个名词严格的讲在今天有两个定义，第一个是泛指机器智能，也就是任何可以让计算机通过图灵测试的方法，包括数据驱动方法。第二个是狭义上的概念，即20世纪五六十年代特定的研究机器智能的方法。传统的人工智能就是首先了解人类是如何产生智能的，然后让计算机按照人的思路去做。

那么传统的人工智能方法是什么呢？简单地讲，就是首先了解人类是如何产生智能的，然后让计算机按照人的思路去做。今天几乎所有的科学家都不坚持"机器要像人一样思考才能获得智能"，但是很多的门外汉在谈到人工智能时依然想象着"机器在像我们那样思考"，这让他们既兴奋又担心。事实上，当我们回到图灵博士描述机器智能的原点时就能发现，机器智能最重要的是能够解决人脑所能解决的问题，而不在于是否需要采用和人一样的方法。

到了20世纪70年代，人类开始尝试机器智能的另一条发展道路，即采用数据驱动和超级计算的方法，而这个尝试始于工业界而非大学。 
在那个年代，IBM在全世界计算机乃至整个IT产业可以说是处于独孤求败的地位。20世纪60年代末，IBM的市值达到500亿美元，这在当时是个很大的数目，占到了美国GDP（国内生产总值）的3%以上。当时，全世界制造大型计算机的只有8家公司，它们被比喻成白雪公主和7个矮人。白雪公主是IBM，7个矮人是其他7家公司。

贾里尼克认为，人的大脑是一个信息源，从思考到找到合适的语句，再通过发音说出来，是一个编码的过程，经过媒介（声道、空气或者电话线、扬声器等）传播到听众耳朵里，是经过了一个长长的信道的信息传播问题，最后听话人把它听懂，是一个解码的过程。既然是一个典型的通信问题，就可以用解决通信问题的方法来解决，为此贾里尼克用两个数学模型（马尔可夫模型）分别描述信源和信道。至于计算机识别时需要从语音中提取出什么特征，贾里尼克的想法很简单，数字通信采用什么特征，语音识别就采用什么特征。这样，贾里尼克就用当时已经颇为成熟的数字通信的各种技术来实现语音识别，而彻底抛开了人工智能的那一套做法。

贾里尼克认为，人的大脑是一个信息源，从思考到找到合适的语句，再通过发音说出来，是一个编码的过程，经过媒介(声道、空气或者电话线、扬声器等)传播到听众耳朵里，是经过了    个长长的信道的信息传播问题，最后听话人把它听懂，是一个解码的过程。既然是一个典型的通信问题，就可以用解决通信问题的方法来解决，为此贾里尼克用两个数学模型(马尔可夫模型分别描述信源和信道。至于计算机识别时需要从语音中提取什么特征，贾里尼克的想法很简单，数字通信采用什么特征，语音识别就采用什么特征。这样，贾里尼克就用当时已经颇为成熟的数字通信的各种技术来实现语音识别，而彻底抛开了人工智能的那    套做法。

大数据的特征：1、体量大。2、多维度。3、完备性

大数据最明显的特征是体量大，这一点无论是内行还是外行都认可，没有什么异议。但是仅仅有大量的数据并不一定是大数据。
其次，多样性虽然是大数据的一个特征，但是含义上有歧义性，其中最重要的含义是多维度。实际上，多维度的讲法更加简明而准确。因此，在不引起混清的情况下，我们今后把 variety 解释成多维度。
大数据的第三个重要特征，也是人们常常忽视的，就是它的全面性，或者说完备性。

大数据的最后一个，或许也是最重要的一个特点，通过分析它名称的英文写法就能够知道。英语里的 large 和 big 翻译成中文都是大的意思，因此很少有人关心为什么大数据使用"big data"这个英语词组，而不是"large data"。但是，在大数据被提出之前，很多通过收集和处理大量数据进行科学研究的论文，都采用 large 或者 vast （海量）这两个英文单词，而不是 big。比如我们常可以看到论文的标题包含“large Scaled...” “Vast Data..." "Large Amount..."等词组，但是很少用 Big。 
那么 big，Iarge 和 vast 到底有什么差別呢。large 和 vast 在程度上略有差别，后者可以看成是 very large 的意思。而 big 和它们的差别在于，big 更强调的是相对小的大，是抽象意义上的大，而 large 和 vast 常常用于形容体量的大小。比如"large table"常常表示一张桌子尺寸很大，而如果说"big table"其实是要表示这不是一张小桌子，真实尺寸是否很大倒不一定，但是这样的说法是要强调已经称得上大了，比较抽象。 
仔细推敲英语中 big data 这种说法，我们不得不承认这个提法非常准确，它最重要的是传递了一种信息——大数据是一种思维方式的改变。现在的数据量相比过去大了很多，量变带来了质变，思维方式、做事情的方法就应该和以往有所不同。这其实是帮助我们理解大数据概念的一把钥匙。

过去交通路况信息发布的流程：少量零散信息，传递到城市交通中心，再发布给地图服务提供者，最终到达地图和交通信息使用者。

英语里的large和big翻译成中文都是大的意思，因此很少有人关心为什么大数据使用“big data”，而不是“large data”……big和它们（large和vast）的差别在于，big更强调的是相对小的大，是抽象意义上的大，而large和vast常常用于形容体量的大小……仔细推敲英语中big data这种说法，我们不得不承认这个提法非常准确，它最重要的是传递了一种信息——大数据是一种思维方式的改变。

大数据是一种思维方式的改变。现在的数据量相比过去大了很多，量变带来了质变，思维方式、做事情的方法就应该和以往有所不同。

在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案这便是大数据思维的核心。

在方法论层面，大数据也是一种全新的思维方式。按照大数据的思维方式，我们做事情的方式与方法需要从根本上改变。

第一，世界变化的规律是确定的；第二，因为有确定性做保障，因此规律不仅可以被认识，而且可以用简单的公式或者语言描述清楚；第三，这些规律是放之四海而皆准的，可以应用到各种未知领域指导实践。

在当时人们的眼里，世界上任何事情都可以用机械来实现，只是实践早晚而已。机械思维更广泛的影响力是作为一种准则指导人们的行为，其核心思想可以概括为确定性（或者可预测性）和因果关系。

首先，并非所有的规律都可以用简单的原理描述。其次，像过去那样找到因果关系已经变得非常困难，因为简单的因果关系规律已经被发现了，另外随着人类多世界认识得越来越清楚，人们发现世界本身存在着很大的不确定性，并非如过去想象的那样一切都是可以确定的。

首先是当我们对这个世界的方方面面了解得越来越细致之后，会发现影响世界得变量其实非常多，已经无法通过简单得办法或公式算出结果。第二个因素来自于客观世界本身，它是宇宙的一个特性。

与机械思维是建立在一种确定性基础上所截然不同的是，信息论完全是建立在不确定性基础上，而要想消除这种不确定性，就要引入信息。至于要引入多少信息，则要看系统中的不确定性有多大。这种思路成为信息时代做事的根本方法。

人类在机器智能领域的成就，其实就是不断地把各种职能问题转化为消除不确定性的问题，然后再找到能够消除相应不确定性的信息，如此而已。
关于信息论，还有一个原理必须了解，那就是“最大熵原理”。大意是说，当我们要对未知事件寻找一个概率模型时，这个模型应当满足我们所有已经看到的数据，但是对未知的情况不做任何主观假设。

在大数据时代，我们能够得益于一种新的思维方法——从大量的数据中直接找到答案，即使不知道原因。

在无法确定因果关系是时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想指导的答案，这便是大数据思维的核心。

欧洲之所以能够在科学上领先于世界其他地方，在很大程度上是依靠从古希腊建立起来的思辨的思想和逻辑推理的能力，依靠它们可以从实践中总结出最基本的公理，然后通过因果逻辑构建起整个科学的大厦。

可以毫不夸张地讲，在过去的三个多世纪里，机械思维可以算得上是人类总结出的最重要的思维方式，也是现代文明的基础。

机械思维的形成可以追溯至古希腊。欧洲之所以能够在科学上领先于世界其他地方，在很大程度上是依靠从古希腊建立起来的思辨的思想和逻辑推理的能力，依靠它们可以从实践中总结出最基本的公理，然后通过因果逻辑构建起整个科学的大厦。其中最有代表性的是欧几里得的几何学和托勒密的地心说。
但是在当时世界上其他的任何文明都没有建立起公理化体系的知识结构，因此对世界的了解免不了支离破碎。
托勒密的思想影响了西方世界一千多年，这倒不完全是因为他的地心说，而是他这种思维方式和方法论。
思维方式和方法远不如方法论对科学的发展至关重要，东方的文明长期以来在技术上领先于西方，但是在科学体系的建立上远远落后于西方，关键是输在方法论上。

写书表达思想是一件颇为主观的事情， 最重要的不是避免犯错误，而是不可缺乏思想。

写书表达思想是一件颇为主观的事情，最重要的不是避免犯错误，而是不可缺乏思想。

写书表达思想是一件颇为主观的事情，最重要的不是避免犯错误，而是不可缺乏思想。

思维方式和方法远不如方法论对科学的发展至关重要，东方的文明长期以来在技术上领先于西方，但是在科学体系的建立上远远落后于西方，关键是输在方法论上。

思维方式和方法远不如方法论对科学的发展至关重要，东方的文明长期以来在技术上领先于西方，但是在科学体系的建立上远远落后于西方，关键是输在方法论上。

牛顿通过自己的伟大成就宣告了科学时代的来临，作为思想家，他让人们相信世界万物的运动变化规律是可以被认识的。他告诉人们:世界万物是运动的，而且这些运动遵循着确定性的规律，这些规律又是可以被认识的。牛顿的这些发现，给人类带来了从未有过的自信。在牛顿之前，人类对自己能否认识自然是缺乏信心的，那些我们们今天看似不需要解释的自然现象，比如苹果为什么会落地，日月星辰为什么升起又落下，在当时却是无法被人们认识的，因此人类对自然恐惧而迷信。

牛顿通过自己的伟大成就宣告了科学时代的来临，作为思想家，他让人们相信世界万物的运动变化规律是可以被认识的。他告诉人们：世界万物是运动的，而且这些运动遵循着确定性的规律，这些规律又是可以被认识的。牛顿的这些发现，给人类带来了从未有过的自信。在牛顿之前，人类对自己能否认识自然是缺乏信心的，那些我们今天看似不需要解释的自然现象，比如苹果为什么会落地，日月星辰为什么升起又落下，在当时却是无法被人们认识的，因此人类对自然恐惧而迷信。直到牛顿出现，人们才开始摆脱这种在大自然面前被动的状态，能够主动地应用科学来把握未来。与牛顿同时代的大科学家哈雷利用牛顿提出的原理，计算出了一颗彗星围绕太阳运转的周期，以及彗星每一次造访地球的时间，这颗彗星后来就用他的名字命名了。后人利用牛顿的理论，能够精确地预测出1000年后出现日食和月食的时间，这在过去是无法想象的。这也同时让确定性这个词深深地印入了人类的思想中。

因为在欧美人看来，牛顿不仅是一位杰出的科学家，而且是人类历史上最重要的思想家之一。
牛顿通过他在数学、物理学、天文学和光学等诸多领域开创性的成绩，总结出一种全新的方法论，不仅开创了科学的时代、理性的时代，而且开启了西方的近代社会。
牛顿通过自己的伟大成就宣告了科学时代的来临，作为思想家，他让人们相信世界万物的运动变化规律是可以被认识的。
牛顿作为思想家的贡献还在于他指出了任何正确的理论从形式上讲都是简单的，同时又有非常好的通用性，这与东方哲学中的大道至简思想不谋而合。

人们将牛顿的方法论概括为机械思维，其核心思想可以概括成这样几句话：

后来人们将牛顿的方法论概括为机械思维，其核心思想可以概括成这样几句话
    第一，世界变化的规律是确定的，这一点从托勒密到牛顿大家都认可。
第二，因为有确定性做保障，因此规律不仅是可以被认识的而且可以用简单的公式或者语言描述清楚。这一点在牛顿之前大部分人并不认可，而是简单地把规律归结为神的作用。
    第三，这些规律应该是放之四海而皆准的，可以应用到各种未知领域指导实践，这种认识是在牛顿之后才才有的。

机械思维更广泛的影响力是作为一种准则指导人们的行为，其核心思想可以概括成确定性（或者可预测性）和因果关系。

机械思维更广泛的影响力是作为一种准则指导人们的行为，其核心思想可以概括成确定性(或者可预测性)和因果关系。

机械思维更广泛的影响力是作为一种准则指导人们的行为，其核心思想可以概括成确定性（或者可预测性）和因果关系。

牛顿的物理学理论是建立在确定性基础，即所谓的绝对时空之上的。爱因斯坦的研究方式是类似的，他的理论也是建立在一种确定性——光速恒定的基础之上的，基于这种假设，利用逻辑推理，就可以推导出整个狭义相对论。

机械思维的两面性——善于把握确定性而难以解决不确定性问题

在制药这个行业，直到今天其核心的方法都遵循"研究病理找到真正致病的原因， 然后针对这个原因找到解决方案"。
青零素和其他抗生素的发明，实际上遵循了"分析找到原因，根据原因得到结果"的思维方式，或者说知其然也知其所以然。这种方法带来的好处是有目共睹的，工业革命后人类寿命的提高都是依靠这种方法。相反，传统医学常常不遵循因果关系，是"不知其所以然"，因此治病的效果也是时好时坏，然后医生们用一些似是而非的语言解释他们其实并没有搞清楚的原因。

从牛顿开始，人类社会的进步在很大程度上得益于机械思维，但是到了信息时代，它的局限性也越来越明显。首先，并非所有的规律都可以用简单的原理描述；其次，像过去那样找到因果关系已经变得非常困难，因为简单的因果关系规律性都被发现了。另外，随着人类对世界认识得越来越清楚，人们发现世界本身存在着很大的不确定性，并非如过去想象的那样一切都是可以确定的。

世界的不确定性来自两方面，首先是当我们对这个世界的方方面面了解得越来越细致之后，会发现影响世界的变量其实非常多，已经无法通过简单的办法或者公式算出结果，因此我们宁愿采用一些针对随机事件的方法来处理它们，人为地把它们归为不确定的一类。
不确定性的第二个因素来自客观世界本身，它是宇宙的一个特性。
在量子力学中有一个测不准原理，也就是说，像电子这样的基本粒子的位置的测量误差和动量的测量误差的乘积不可能无限小。这与机械思维所认定的世界的确定性是相违背的。为什么会有这样的现象存在呢?因为我们测量活动本身影响了被测量的结果。对于股市上的操作也类似，当有人按照某个理论买或者卖股票时，其实给股市带来了一个相反的推动力，这导致股市在微观上的走向和理论预测的方向相反

在现实生活中情况也是类似的，不论是因为数据量太大导致的不确定性，还是因为世界本身带有的不确定性，总之，世界上很多事情是难以用确定的公式或者规则来表示的。但是，它们并非没有规律可循，通常可以用概率模型来描述。在概率论的基础上，香农博士建立起一套完整的理论，将世界的不确定性和信息联系了起来，这就是信息论。信息论不仅仅是通信的理论，也给了人们一种看待世界和处理间题的新思路。

“熵”来描述一个系统中趋向于恒温的温度。当这个系统完全达到恒温时，就无法做功了，这时熵最大。

接下来香农指出，信息量与不确定性有关:假如我们们需要搞清楚一件非常不确定的事，或是我们一无所知的事情，就需要了解大量的信息。相反，如果我们对某件事已经有了较多的了解，那么不需要太多的信息就能把它搞清楚。所以，从这个角度来看，可以认为，信息量的度量就等于不确定性的多少，这样香农就把熵和和信息量联系起来了。他还指出要想消除系统内的不确定性，就要引引入信息。

但是，信息论的作用远不止在科学和工程上——它也是一种全新的方法论。与机械思维是建立在一种确定性的基础上所截然不同的是，信息论完全是建立在不确定性基础上，而要想消除这种不确定性，就要引入信息。至于要引入多少信息，则要看系统中的不确定性有多大。

虽然香农提出信息论最初的目的只是建立通信的科学理论，但是，信息论的作用远不止在科学和工程上——它也是一种全新的方法论。与机械思维是建立在一种确定性的基础上所截然不同的是，信息论完全是建立在不确定性基础上，而要想消除这种不确定性，就要引入信息。至于要引入多少信息，则要看系统中的不确定性有多大。这种思路成为信息时代做事情的根本方法。

谁掌握了信息，谁就能够获取财富，这就如同在工业时代，谁掌握了资本谁就能获取财富一样。

在我们对用户一无所知的情况下，在网页上投放展示广告，点击率非常低，每1000次展示也只能赚不到0.5美元的广告费，因为这等于随机猜测用户的需求，很不准确。如果我们有10万种广告，只有10种与用户相关，那么猜中的可能性就是万分之 。如果用信息论的方法来度量，它的不确定性为14比特左右。搜索广告因为有用户输入的关键词，准确率会大幅提高，至于提高了多少，取决于关键词所提供的信息量。以汉字词为例，如果一个搜索输入了两个词，每个词平均两个汉字，那么大约能提供10~12比特的信息量，这样大部分不确定性就消除了。假定还是从10万种广告中猜10个，这时猜中的可能性就是十几分之到几分之一，因此读者点击广告的可能性大增。在实际情况中， Google搜素广告每100次展示所带来的收入大约是50美元，比展示广告高出两个数量级。这就说明了信息的作用。类似地，我们大致计算出，像 Facebook或者 Google通过挖掘注册用户的使用习惯，大约能够获得1~2比特的信息量，这样就将广告匹配的难度下降了大约一半，事实上，那些与用户相关的展示广告比完全随机的正好产生高一倍左右的广告收入。

谁掌握了信息，谁就能够获取财富，这就如同在工业时代谁掌握了资本谁就能获取财富一样。 
当然，用不确定性这种眼光看待世界，再用信息消除不确性，不仅能够赚钱，而且能够把很多智能型的问题转化成信息外延的问题，具体说，就是利用信息来消除不确定性的问题。

我们在利用信息时使用的很多原理和方法，在信息论中都能找到根据。比如用信息论中的一个重要概念——互信息（Muhal Information),可以解释为什么信息的相关性可以帮助我们解决很多问题。在很多时候，我们能够获取的信息和要研究的事物并非一回事，它们之间必须"有关联"，所获得的信息才能帮助我们消除不确定性，搞清楚我们想要研究的问题。比如前面提到的王进喜的照片和大庆油田的位置、产量等情报就属于有关联。当然 "有关联"这种说法太模糊，不科学，最好能够量化地度量两件事之间的"相关性"。为此，在信息论里用互信息这个概念，实现了对相关性的量化度量。比如通过对大数据文本进行统计就会发现， "央行调整利率"和"股市短期浮动"的互信息很大，这证实了它们之间有非常强的相关性。而"央行调整利率"和"北京机场大量航班晚点"的互信息则接近于零，说明二者没有什么相关性， 甚至无关。

关于信息论，还有一个原理必须了解，那就是最大熵原理。这个原理的大意是说，当我们要对未知的事件寻找一个概率模时，这个模型应当满足我们]所有已经看到的数据，但是对未知情况不要做任何主观假设。

最大嫡原理要比任何人为假定的理论更有效，因此它被广泛地于机器学习。最大熵原理实际上已经不同于我们使用了几百年大胆假设、小心求证”的方法论，因为它要求不引入主观的设。当然，不做主观假设的前提是取得了足够多的数据，否则大熵模型只能给出一些平均值而已，而不能对任何细节进行描和预测
    今天，信息论已经被广泛地用于管理，因为它为我们提供信息时代的方法论。而熵这个词，也成了信息论和不确定性的名词。也正是因为如此，张首晟教授和我都认为它代表了人我们的世界认知度的最高境界。

美国一共只有5000多种处方药，人类会得的疾病大约有一万种。

2001年，当全球互联网泡沫破碎后，大家都在逃离这个领域，很多人从互联网行业回到了学水界。人们问我为什么在这样一个时候离开NASA (美国国家航空航天局），加入Google这家不大的互联网公司。我和他们讲了大萧条时期 (1929—1933年）的一个故事。在大萧条时，有些人买了银行的股票，后来都发了财。事后人们问那些买了银行股票的人为什么在银行如此精糕时敢买它们的股票，那些投资人讲， "因为全世界的钱都在它们那里。”所以，加入Google的决定并不难做，因为全世界的数据都在Google那里。

即对于不同的搜索关键词，用户们都点击了哪些搜素结果(网页)。比如对于“虚拟现实”这个查询，用户有3100次点击了网页A1500次点击了网页B，11000次点击了网页C…在这种情况下网页A应该被排在第一位，但是如果搜素排序算法不好，有可能出现它没有被排在第一位的情况。这时搜素引擎的设计者就面临一个选择，是采用通过研究改进原有的排序算法，还是干脆相信用户的点击结果，或者是将它们结合在一起。如果单纯改进排序算法，这个周期特别长。如果相信用户点击的结果，其实就是用相关性取代罗果关系，当然这里面有两个风险:首先是用户点击容易形酸马太效应，排在前面的结果即使不是很相关，也容易获得更多的点击;    次是单纯依靠点击，搜索结果的排名容易被一些使用者操纵。因此，比较稳妥的办法是对用户的点击数据建立一个简单的模型，作为搜素排序算法的一部分。
    今天，各个搜索引擎都有一个度量用户点击数据和搜索结果相关性的模型，通常被称为点击模型”随着数据量的积累，点击模型对搜索结果排名的预测越来越准确，它的重要性也越来越大。今天，它在搜索排序中至少占709%~80%的权重，也就是说素算法中其他所有的因素加起来都不如它重要。换句适
今天的搜素引擎中，因果关系已经没有数据的相关性重要一    ①各家搜素引擎对点击模型的依赖权重虽然有大有小，但是都在60%以上。

当整个搜索行业都意识到点击数据的重要性后，这个市场上的竞争就从技术竟争变成了数据竟争。这时，各公司的商业策略和产品策略就都围绕着获取数据、建立相关性而开展了。后进入搜索市场的公司要想不坐以待毙，唯一的办法就是快速获得数据。比如微软通过接手雅虎的搜索业务，将必应的搜索量从原来 Google的10%左右陡然提升到 Google的20%~309%，点击模型估计得准确了许多，搜索质量迅速提高。但是即使做到这一点还是不够的，因此一些公司想出了更激进的办法，通过搜索条 Toolbar)、浏览器甚至输入法来收集用户的点击行为。这种办法的好处在于它不仅可以收集到用户使用该公司搜素引擎本身的点击数据，而且还能收集用户使用其他搜索引擎的数据，比如微软通过IE浏览器收集用户使用 Google搜索时的点击情况。这样一来，如果一家公司能够在浏览器市场占很大的份额，即使它的搜索量很小，也能收集大量的数据。有了这些数据，尤其是用户在更好的搜索引擎上的点击数据，一家搜索引擎公司可以快速改进长尾搜素的质量。当然，有人诟病必应的这种做法是“抄” Google的搜索结果，其实它并没有直接抄，而是用 Google的数据改进自已的点击模型。这种事情在中国市场上也是一样，因此，搜索质量的竟争就成了浏览器或者其他客户端软件市场占有率的竟争。虽然在外人看来这些互联网公司竞争的是技术，但更准确地讲，它们是在数据层面竞争。

Google和很多互联网公司之所以能够取得成功，不仅仅依靠技术，靠数据，更是靠采用了大数据时代的方法论，或者说大数据思维。作为数据公司，它们在做事情的方法上有着和传统工业公司不同的思维方式。相对来讲这些公司很少花大量的时间和资源来寻找确定的因果关系，而是通过从大量数据中挖掘相关性，直接用于产品，因此它们给外界的感觉是产品更新非常快。

机械思维曾经是改变了人类工作方式的革命性的方法论，并且在工业革命和后来全球工业化的过程中起到了决定性的作用，今天它在很多地方依然能指导我们的行动。如果我们们能够找到确定性(或者可预测性)和因因果关系，这依然是最好的结果。但是今天我们面临的复杂情况，已经不是机械时代用几个定律就能讲清楚的了，不确定性，或者说难以找到确定性，是今天社会的常态。在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案，这便是大数据思维的核心。大数据思维和原有机械思维并非完全对立，它更多的是对后者的补充。在新的时代，一定需要新的方法论，也一定会产生新的方法论。

很多时候，落后与先进的差距，不是购买一些机器或者引进一些技术就能够弥补的，落后最可怕的地方是思维方式的落后。西方在近代走在了世界前列，很大程度上靠的是思维方式全面领先。 
机械思维曾经是改变了人类工作方式的革命性的方法论，并且在工业革命和后来全球工业化的过程中起到了决定性的作用， 今天它在很多地方依然能指导我们的行动。如果我们能够找到确定性（或者可预测性）和因果关系，这依然是最好的结果。但是，今天我们面临的复杂情况，已经不是机械时代用几个定律就能讲清楚的了，不确定性，或者说难以找到确定性，是今天社会的常态。在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案，这便是大数据思维的核心。大数据思维和原有机械思维并非完全对立，它更多的是对后者的补充。在新的时代，一定需要新的方法论，也一定会产生新的方法论。

无法确定因果关系时，数据中所包含的信息可以帮助我们消除不确定性，数据之间的相关性可以在某种程度上取代原来的因果关系，帮助我们得到我们想知道的答案，这便是大数据思维的核心。

今天我们面临的复杂情况，已经不是机械时代用几个定律就能讲清楚的了，不确定性，或者说难以找到确定性，是今天社会的常态。在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案，这便是大数据思维的核心。

在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案，这便是大数据思维的核心。大数据思维和原有机械思维并非完全对立，它更多的是对后者的补充。在新的时代，一定需要新的方法论，也一定会产生新的方法论。

今天我们面临的复杂情况，已经不是机械时代用几个定律就能讲清楚的了，不确定性，或者说难以找到确定性，是今天社会的常态。在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我们消除不确定性，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案，这便是大数据思维的核心。大数据思维和原有机械思维并非完全对立，它更多的是对后者的补充。在新的时代，一定需要新的方法论，也一定会产生新的方法论。

在无法确定因果关系时，数据为我们提供了解决问题的新方法，数据中所包含的信息可以帮助我偵消除不确定愽，而数据之间的相关性在某种程度上可以取代原来的因果关系，帮助我们得到我们想知道的答案，这便是大数据思维的核心。大数据思维和原有机械思维并非完全对立，它更多的是对后者的补充。在新的时代，一定需要新的方法论，也一定会产生新的方法论。

我们看到了大数据思维的三个亮点：第一是用统计规律和个案对比，做到精准定位；第二是社会其实已经默认了在取证时利用相关性代替直接证据，即强相关性代替因果关系；第三是执法的成本，或者更广泛地讲，运用的成本，在大数据时代会大幅下降。
先从大数据找到普遍规律，然后再应用于每一个具体的用户，并且影响到每一个具体的操作。

大数据在商业活动中从细节到整体再从整体到细节双向的流动，使得我们不仅能够利用大数据多商业进行整体提升，更能够精确到每一个细节。
在过去，统计学家们一直试图寻找好的采样方法，以便在有限的样本中找到覆盖尽可能全的规律，但是在大数据时代，这些努力都不需要了，因此样本集可以等于全集。

对google自动驾驶汽车的各种报道通常都会忽视一个事实，那就是它只能去google“扫过街”的地方，对于这些已经去过的地方，google都收集了非常完备的信息，比如周围各种目标的大小、颜色，每条街的宽窄、限速，不同时间的交通情况、人流密度等，google都事先处理好以备未来使用。因此，自动驾驶汽车每到一处，对周围的环境是非常了解的，它可以迅速把这些数据调出来作为参考。而过去那种研究所里研制的自动驾驶汽车使用的是人的思维方式，每到一处都要临时识别目标，这样即使所搭载的计算机再快，也来不及进行太深入的计算，因此无法做出准确判断。

在今天大数据和机器职能的时代，虽然每一个公司都会得益于数据的使用以及机器职能带来的好处，但这并不意味着每家公司都要聘请数据科学家或者机器智能方面的专家。更切合实际的是，他们付费使用第三方服务。在未来们可以看到，大数据和机器智能的工具就如同水和电这样的资源，由专门的公司提供给全社会使用。

相比电子商务公司，塔吉特的IT—力量并不强，而且作为传统的连锁店，它所收集到的与用户行为相关的数据并不算多，即便如此，在使用大数据之后，它比客户的家庭更了解自家的情况。那些手握更多数据的电子商务公司，诸如亚马逊和阿里巴巴，就更可能比我们更了解我们自己的需求了。

2015年7月，亚马逊的市值超过了沃尔玛，这标志着一个新时代的到来——以大数据为基础的电子商务将超越传统的零售商业。后者并非不能利用大数据，只是在个性化和时效性等方面，很难做得像电子商务公司那么有效而已。

在 亚马逊开始做商品推荐的初期，由于数据量不足，不得不采用不需要太大数据 量的同类顾客归类的推荐方式。事实证明将顾客聚类的方式效果非常不好，最终亚马逊不得不放弃这种方式。好在随着亚马逊数据量的积累，它可以采用直接但是需要非常大量数据的方法，即它所谓的“由商品直接推荐商品” (Item to Item)，这才使得亚马逊的推荐系统变 得准确而有时效性。

戴维是硅谷地区一位创业者，他喜欢根据技术发展的大趋势寻找特定领域里的商机。我在见到他之前他已经创办过两家公司，    家公司表现平平，于是他在经营到第四个年头时不得不将它关闭。但是戴维的第二家公司经营得不错，并且在5年后被一家大公司收购了，这样戴维获得了财务上的自由。戴维在接下来的年里走访了美国100多家酒吧，然后考虑如何利用大数据和移动互联网来帮助它们提升业务。在美国，一半小型企业(包括餐馆等)的寿命不超过5年，酒吧也是如此。戴维发现它们之所以经营不下去，除了一般所说的经营不善，更重要的是大约23%的酒都被酒保们偷喝了。
    那么酒保们是如何偷喝掉将近1/4的酒的呢?戴维说，这其实很简单，主要是酒保们趁老板不在的时侯偷喝酒，或者给熟人朋友免费的和超量的酒饮。比如小王是酒保，小李是他的朋友这天小李来到酒吧时，小王看老板不在，就给小李倒上一杯没有算钱。甚至即使老板在，小王本来该给小李倒4两酒，结果倒了6两。由于每一次交易的损失都非常小，不易察觉，因此在过去酒吧的老板平时必须町得紧一点，如果有事离开一会儿，只好认倒霉。
        开过小餐馆的人都会有这样的经验，自己是否在店里看着对营业额的影响特别大，因此做这种餐饮买卖的人特别辛苦，稍微不注意就开始亏损。针对酒吧老板的这些麻烦，戴维设计了套解决方案一一改造酒吧的酒架，装上可以测量重量的传感器，以及无源的射频识别芯片(RFID)°的读写器，然后再在每个酒瓶上贴上一个RFID的芯片。这样，哪一瓶酒在什么时候被动过，倾倒了多少酒都会被记录下来，并且和每一笔交易匹配上。酒吧的老板可以用平板电脑查询每一笔交易，因此即使出门办事也可以了解酒吧经营的每一个细节。
    当然，戴维提供的服务如果只是停留在这个层面，那么更像是一个“万物联网”( Internet of things，简称loT)的应用，与我所说的大数据其实关系...

RFID是一种不需要电源的芯片，里面存储的信息可以被专门的阅读器发出的无线电波探测出来。

中国的金风公司是一家生产风能发电设备的公司，2015年时它的风能发电机在全世界的占有率已经排到第二位，这是一个相当好的业绩。

在过去，统计学家们一直试图寻找好的采样方法，以便在有限的样本中找到覆盖尽可能全的规律，但是在大数据时代，这些努力都不需要了，因此样本集可以等于全集。另外，我们还可以从这个案例中看到大数据时效性的特点。对于全新的、过去没有见过的情况，Google的服务器是反应非常及时的，即在第二次就能把新鲜的数据提供给用户使用。

在历史上，一项技术带动整个社会变革的事情也曾经发生过。 它们通常遵循一个模式，即:
新技术+原有产业=新产业 
那些有意或者无意接受了这个规律的企业家，常常在新的时代又站到了浪潮之颠。

如果我们把证券行业和IT行业做类比就会发现一个有趣的现象：在纳斯达克出现之前，券商好比是生产大型设备的IT公司，它们每一笔交易都可以获得丰厚的利润，这就如同IT公司当时每卖出去一件产品，就都可以挣很多钱一样。但是，后来低端的券商靠价格优势抢了高端券商的生意，逼着高端券商从事理财这样的金融服务，就如同亚洲制造的电脑公司靠价格优势逼着IBM和惠普从事IT服务一样。从这个趋势可以看出，各种服务在信息革命之后变得越来越重要。

未来产品的服务水平不完全取决于厂商对它的重视程度（比如服务态度）和相关技术，而更多要依靠智能化。未来，商家将在数据层面和智能化方面展开竞争。

更切合实际的是，他们付费使用第三方的服务。在未来我们可以看到大数据和机器智能的工具就如同水和电这样的资源，由专门的公司提供给全社会使用。

在今天大数据和机器智能的时代，虽然每一个公司都会得益于数据的使用以及机器智能带来的好处，但这并不意味着每家公司都要聘请数据科学家或者机器智能方面的专家。更切合实际的是，他们付费使用第三方的服务。在未来我们可以看到，大数据和机器智能的工具就如同水和电这样的资源，由专门的公司提供给全社会使用。

首先，是大部分现有产业加上新技术等于新产业。或者说原有产业需要以新的形态出现。其次，并非每一家公司都要从事新技术产品本身的制造，更多时候它]是利用新技术改造原有产业。这次以大数据为核心的智能革命也不例外，我们将看到它依然会延续这两个特点。每次技术革命都会诞生新的思维方式和商业模式，企业只有在思维上跟上新的时代，才能在未来的商业中立于不败之地。

大数据的数据量大、维度多数据完备等特点，使得它从收集开始，到存储和处理，再到应用，都与过去的数据方法有很大的不同。因此，使用好大数据也需要在技术和工程上采用与过去不同的方法。

科学技术的发展并不是匀速的。重大的科技突破常常需要酝酿很长的时间。当量积累到一定程度后，科技在短时间内获得单点突破，然后新科技全面迸发，这便是拐点。机器智能的概念已经被提出来60多年了，但是真正的突破却在有了大数据时代的今天。

首先，传统的数据方法常常是先有一个目的，然后开始收集数据。而在大数据时代，收集数据时常常没有预先设定的目标，而是先把所有能够收集到的数据收集起来，再进行分析，得出什么结论就是什么结论。
另一个不同在于，过去我们时通过少量的采样获得所谓具有代表性的数据，而大数据则避免了采样之苦，因为其常常以全集作为样本集。

需要技术解决方案来提高存储的效率，保证不断产生出来的数据都能够存储下。
还需要研究怎样存储信息才能便于使用。

大数据面临的另一个技术难题就是如何标准化数据格式，以便共享。

在历史上有很多关键性的拐点，比如166年，牛顿发明了微积分，发现了力学三定律和万有引力定律，完成了光学分析，从此世界进入科学近代社会，因此这一年这被看成是科学史上的一个拐点。到了1905年，爱因斯坦完成了分子说，发现了光电效应，提出了狭义相对论，从此开启科学的现代社会，随后物理学的各个领域全面繁荣。1965年，摩尔博士提出了摩尔定律，同时在工业界大规模集成电路出现现，从此开始了持续半个世纪的信息产业高速发展。在这些拐点上，原有的平衡被迅速打破，人类从此进入一个新的时代。

机器智能的概念已经被提出来60多年了，但是真正的突破却在具有了大数据的今天。大数据本身真正引起科技行业的注意，也仅仅是十年前的事情，然而在短短的几年里，它就井喷式地爆发了，并且让机器智能水平有了本质的提高。因此智能技术的拐点可能就发生在从10年前开始到接下来的一二十年这一段时间。再过一两个世纪，回顾我们今天所处的时代，后人会感叹这是人类文明史上的一个大时代，就如同我们今天谈论大航海时代和工业革命那样。

大数据的第一个来源是电脑本身。全球数字化让几乎每一个使用电的设备都有了一个"电脑"，这些电脑或者设备中内置的处理器、传感器和控制器一直在产生数据，比如记录设备状态的日志（Log)。在过去，很多数据并不会被记录下来，比如电话交换 机除了记录少量的设备运行状态之外，并不记录来往通话的控制信息，包括打电话的时间、双方的电话号码、通话时长等，但是当人们发现这些数据有价值之后，由计算机控制的程控交换机很容易把这些细节都记录下来，这就产生了很多和电信相关的数据。

大数据的第二个来源是传感器。传感器技术的进步使得收集数据变得非常容易。我们在前一章中提到无源的射频识別芯片(RFID)就是一种帮助收集数据的工具。今天无所不在的摄像头，其作用与收集数据的传感器也有着相似之处。

大数据的第三个来源是将那些过去已经存在的、以非数字化形式存储的信息数字化，这一程开始于2000年左右。非数字化的数据包括语音、图片、设计图纸、视频、档案、古稀图书和医学影像等，这些信息过去都是以各种各样的形式存储的，由于积累的时间很长，因此数量巨大。

应用大数据的一个前提就是能够将一个大的计算任务分到很多台便宜的服务器上去做并行计算。单一维度数据的处理不是一件难事，但是大数据有多维度的特点，有时并行化是非常困难的。没有相应的软件支持，很难将一个复杂的大问题拆成很多小问题分配到多台服务器上去做并行计算。并行计算的另一个必要的技术条件是交换机和网络速度得非常快，否则网络就成为计算的瓶颈，服务器的处理器使用效率会非常低下。事实上，市面上能够买到的最快的交换机可能也达不到无传输障碍的海量并行计算的要求。为了提高服务器之间通信的速度,Google需要自己设计最快的交换机。

按照信息论的观点，要消除不确定性就需要信息，因此信息的收集非常关键。大数据与传统的数据统计方法相比，在收集数据方面有了很大的不同。 
首先，传统的数据方法常常是先有一个目的，然后开始收集数据。
在大数据时代，在收集数据时常常没有这样预先设定的目标，而是先把所有能够收集到的数据收集起来 经过分析后，能够得到什么结论就是什么结论。正是因为在收集数据时没有前提和假设，大数据分析才能给我们带来很多预想不到的惊喜，也才使得大家觉得计算机变得很聪明了。 
在获取数据方面，大数据和传统的统计方法另一个不同点在于，过去我们是通过少量的采样获得所谓具有代表性的数据，这些数据被称为样本。根据统计学的原理，只要样本具有代表性，通过分析这些少量的样本数据，就可以总结出规律性。在过去的几个世纪里，科学家们就是这么做的，不过他们在宣布自己从有限数据中获得的规律性具有普遍意义时，很快便有其他科学家会找到反例，在局部范围内推翻原来的理论。这里面固然有人类认知局限性的原因，也有样本数据太少难以具有代表性的因素。
大数据则避免了采样之苦，因为大数据常常以全集作力样本集。但是怎样收集到全集就是—件很有挑战的事情了，因为不能再采用过去抽样调査的方式了。
那么，聪明的公司会怎样解决收集数据的难题呢？最常见的方法就是绕一个弯路，间接地收集数据，然后利用数据的相关性，导出自己所要知道的信息。但是这条路并不好走。

在数据的收集过程中，非常忌讳那种"大胆假设，小心求证"的思维方式，因为在很多时候，如果事先有了定论，再找数据来证实它，总能找到有利的证据，而这些看似被数据证实的结论，很可能与真实情况相差十万八千里。

信息存储相关技术并不局限在研究如何节省存储量上，还需要研究怎祥存储信息才能便于使用。在大数据之前，人们在设计文件系统和数据存储格式时，主要考虑的是规模较小、维度较少的结构化的数据。到了大数据时代，不仅数据量和维度都剧增，而且因为大数据在形式上并不遵循计么固定的格式，过去需要重新优化数据的格式，按照过去数据特点优化设计的文件系统对大数据的使用未必是高效率的，因此需要重新设计通用、高效和便捷的数据表示方式和存储方式。
大数据面临的另一个技术难题是如何标准化数据格式便共享。在过去，各个公司都有自己的数据格式，它们只在自己的领域使用自己的数据。但是，到了大数据时代，我们希望通过数据之间的相关性，尤其是大数据多维度的特性，找到各种事物之间的关联。

不仅一家公司正常的业务流程可以学习，当数据量足够大时，每个被授权的使用者的使用习惯也是可以学习的，那么不符合这些习惯的操作就可能来自非法的闯入者，这些操作就会被禁止。
日本一个发明家将这种思路用于汽车的防盗。他发明了一套检测驾驶员身材信息和操作信息的监控系统，能够根据平日里经常驾驶某辆车的人的身材信息、坐姿和动作，判别是原来的司机还是新来的人。如果某个偷车贼偷到了钥匙试图将车开走，那么该系统一旦发现这个人平时没见过，就会要求他输入密码，如果密码输入错误，汽车会完全关闭，不能启动。这种防盗方式和保护信息安全的方式异曲同工。

使用大数据，相当于在一堆沙子中淘金，不经过处理的原始数据是给不出什么新知识的，大数据能产生的效益在很大程度上取决于使用（和挖掘）数据的水平。在Google，至少有四成的工 程师天天在处理数据，然后通过数据得到知识，通过知识使得计 算机变得更智能。 
我们在强调收集大数据是无目的性的同时，也给处理大数据增加了难度。由于大数据的原始数据常常是没有固定格式、显得杂乱无章的，因此使用大数据的第一步是对数据的过滤和整理，去除与要解决的问题无关的维度，将与问题有关的数据内容进行格式化的整理，以便进一步使用。数据的过滤和整理有时很容易， 比如我们希望通过日志分析一款游戏玩家的行为，这只要把相应的维度保留下来，把无关的信息过滤掉即可。但是，在很多应用中，即使这一步也不容易做到。

机器学习的过程无一例外是一个不断迭代、不断进步的过程，用机器学习的专业术语来说就是"期望值最大化"(ExpectatlQn Maximization)的过程：只要事先定出一个学习的目标，这些算法就会不断地优化模型，让它越来越接近真实的情况。可以说，机器学习训练算法迭代的次数越多，或者通浴地说学习得越深入，得到的数学模型效果越好。

机器学习并不是什么新鲜事，今天广泛使用的机器学习算法，比如人工神经网络算法、最大熵模型、逻辑自回归等，早在40年前就已经成熟了。但是由于数据量不够，导致机器学习的应用范围比较窄，再加上它是介于应用数学、统计学和计算机科学之间的交叉领域，因此一直没有受到太大的重视。

在过去，由于计算能力的限制，以及并行计算工具不够有效，人们在机器学习时，通常要在下面两种情况下二选一：
1. 数据量大，但是采用比较简答的模型，而且比较少的迭代次数，也就是说用大量的数据做一个浅层的机器学习；
2. 数据量较小，但是采用比较复杂的模型，而且经过很多次迭代训练出准确的模型参数。
通常，由大量的数据、较少迭代训练出的“较粗糙”的模型，要比用少量的数据，深度的学习精耕细作得到的模型效果要好。

从机器学习理论上来讲，它（Google Brain）没有任何突破，只是把过去的人工神经网络并行地实现了。但是从工程的角度来讲，它有非常大的意义。首先，过去的人工神经网络无法训练很大的模型，即使计算的时间再长也做不到，因为内存中根本放不下和模型参数相关的数据。Google的突破在于找到了一种方法，可以将一个很大的模型上百万参数同时训练的问题，简化为能够分不到上万台（甚至更多）服务器上的小问题，这样使得大型的人工神经网络训练成为可能。当然，Google还找到了（不是发明了）一些对大模型并行训练收效比较快的训练算法，可以在能够接受的时间内，深度训练处一个大型的数学模型。Google在几个带有智能特色的问题上，用这个深度学习的工具对语言识别的参数进行重新训练，就将识别的错误率降低了15%（相对值），这对与机器翻译的效果同样显著。

因此最好的解决方式就是出现一些专门做机器学习的公司，来为需要使用大数据和机器智能的公司提供服务。

机器学习的方法不可能由每家公司自己去研究，最终会有专业的公司为大众提供机器学习的服务。

人们在中国某大型电子商务网站上发现，某些人总是买到假货，而另外一些人以同样价格却买到真货。这并不是因为前者比后者的运气差，而是商家掌握了太多的个人数据，或者说我们的隐私。当商家知道前者是买了假货也不会坑声的软柿子，后者是睚眦必报的刺头的时候，欺软怕硬的行为一定能够给他们带来最多的利益。在利用大数据方面，个人用户相比商家永远是弱势群体，一旦他们的秘密被商家知道，他们的利益就难免受到损害。 美国很多航空公司在利用个人隐私大发其财。当航空公司发现某个机票的询票者最近必须旅行，而且在过去对票价不是很敏感时，它给出的报价就会比给其他人的高很多。尤其当两个城市间仅此一家航空公司有直飞的航班时，价格上的差异就更明显。 这些航空公司甚至出钱聘请了美国一些著名的大学帮助研究这样利用用户隐私赚钱的方法。据一所世界名校里承接这些项目的团队介绍，利用对用户行为的分析，可以让航空公司提高10%左右的销售额。虽然10%的提高听起来不算太多，但是对净利润率只有0.2%的航空业来说，这是几十倍的利润的提高。而对于乘客来说，由于只是部分乘客受到伤害，整体上10%票价的提高意昧着他们的额外支出要远比10%多，实际上多付出的票价可以高达50%。

另一类保护隐私的技术是所谓的双向监视……简单来讲就是当使用者看计算机时，计算机也在盯着使用者看……凯文·凯利对各种保护隐私的技术做过评估，他和研究人员发现，如果给窥视者一个选择，输入自己的真实信息然后才可以窥视他人，那么绝大多数人会选择直接离开。

一类保护隐私的技术是从收集信息的一开始就对数据进行一些预处理，预处理后的数据保留了原来的特性，使得数据科学家和数据工程师能够处理数据，却”读不懂“数据的内容。这样至少能防止个人窃取和泄露隐私，但是并不能限制那些拥有非常多数据的大公司了解每一个人的隐私。
另一类保护隐私的技术是所谓的双向监视。这是一个很新颖的保护隐私的想法，简单地讲就是当使用者看计算机时，计算机也在盯着使用者看。大部分人喜欢偷窥别人隐私的一个原因,，这种行为是没有任何成本的。但是，如果有人在刺探別人隐私时， 他的行为本身暴露了，那么他就会多少约束自己的行为。这就好比一个倫窥者悄悄推开门缝往里面窥视，发现里面有双眼睛正在看着他，那么他的反应可能是马上把门关上。凯文.凯利对各种保护隐私的技术做了评估，他和研究人员发现，如果给窥视者一个择，输入自己的真实信息然后才可以窥视他人，那么绝大多数人会选择直接离开。正如制约权力最好的办法是使用权利，解决一种技术带来的漏洞最好的办法是采用另一种技术，那么保护隐私最好的办法或许是让侵犯隐私的人必须以自己的隐私来做 交换。 
总结上述两种技术的特点，我们可以看出，为了在使用大数据的同时尽可能地保护隐私，数据从采集到使用都需要是双向知情的，也就是说不再是数据的所有者暴露在大庭广众之下，数据的采集者和使用者（偷窥者也是一种特殊的数据使用者）也是同样被监督的，或许这样是最有效地保护隐私的方式。

先有产业+机器智能=新产业。未来的农业、制造业、体育、医疗、律师，甚至编辑记者行业都将迎来崭新的形态，新产业将取代旧产业满足人类的个性化需求，大数据将导致我们整个社会的升级和变迁。

在中国很多患者的心目中，看病要找"老大夫"，因为他们有经验。实际上，老大夫经验的积累就是一个通过病例（数据）学习的过程，而人学习再快，也学不过计算机，这一点我们在前面分析Google的AlphaGo和李世石下棋的案例中已经指出了。 一个放射科大夫一生阅读研究的病例很难超过10万个，而计算机则很谷易从上百万病例中学习。2012年Google科学比赛的第一名授予了一位来自威斯康星的高中生，她通过对760万个乳腺癌患者的样本数据的机器学习来帮助医生对病人进行活检，其位置预测的准确率高达96%，超过目前专科医生的水平。

我们知道，癌细胞是动物和人自身细胞在复制过程中基因出了错，而非来自体外，因此它们与任何动物正常的细胞非常相似。

大数据和机器智能将把我们社会的管理水平提升到一个前所未有的高度

在历次的技术革命中，一个人、一家企业，甚至一个国家，可以选择的道路只有两条：要么加入浪潮，成为前2%的人，要么观望徘徊，被淘汰。

今天医疗领域存在两个怪现象。首先，一方面一些没有什么大病的人要费很大的劲找一个专家看病，他们为了做到这一点要么一大早排队挂号，要么托关系走后门；另一方面确实需要有经验的专家看病的那些病人却得不到相应的医疗资源。其次，另一个怪现象是，那些千方百计找专家看病的人，实际上也不知道找哪个专家，只能根据他们的头衔找所谓最好的，而专家们也常常发现患者其实应该找其他专家而不是他们自己看病。虽然这里面有专家号太便宜的原因，有患者无知的因素，但是没有足够的信息, 以及缺乏一个很好的医疗顾问进行就诊指导也是其中一个重要的原因。

在过去，我们泄露隙私有时是不得已的，比如不能不去看病, 而医生也不能不去问保险公司要钱。但楚在移动互联网时代，尤其是今后万物联网的时代，我们本身就足主动的隐私泄密者。绝大部分智能手机的使用者安装了太多的、很少使用甚至并不必要的App，参加了太多的优惠促销活动。同时，在自以为安全的社交网络说了很多在公众场合不适合说的话，或者发了太多的照片。这些都可能造成人为的隐私泄露。我们还在使用的各种电子产品，从可穿戴设备到带有GPS的照相机，再到与Wi-Fi相连的各种智能电器，不自觉地记录下了我们详细的行踪和生活信息，并且提供给了服务商。很多时候，第三方再通过服务商获得这些信息，也并非难事，究其源头，是我们自己在不设防的情况下把信息泄露出去的。

历史上影响力可以和正在进行的智能革命相比的，只有19世纪末始于英国的工业革命、20世纪末始于美国和德国的第二次工业革命、“二战”后以摩尔定律为标准的信息革命，一共是三次。这三次革命都有一个共同的特点，那就是它们对当时的社会产生了巨大的冲击，都需要经过大约半个世纪甚至更长的时间才能消化掉。

英国人花了大约两代人的时间消化工业革命带来的负面影响。……我们可以把工业革命对社会的影响分成三个阶段：第一个阶段只有发明家和工厂主们受益，普通英国民众并没有受益；第二个阶段是全体英国民主普遍受益，但是在世界范围内大家未必受益，这两个阶段之间相差半个多世纪；第三个阶段才是整个世界受益，这和第二个阶段又相差很长时间。

技术革命会使得很多产业消失，或者产业从业人口大量减少，释放出来的劳动力需要寻找出路。这个时间有多长呢？事实证明至少要一代人以上，因为我们必须承认一个并不愿意承认的事实，那就是被淘汰的产业的从业人员能够进入新行业中的其实非常少。

虽然各国政府都试图通过各种手段帮助那些从业人员掌握新的技能，但是收效甚微，因为上一代人很难适应下一代的技术发展。事实上，消化这些劳动力主要的是等待他们逐渐退出劳务市场，而并非他们真正有了新的出路，能够和以前一样称心如意地工作。这就是每次技术革命都需要花半个世纪来消除它带来的动荡的原因。唯一不同的是，在一百年前，各国政府认识不到关心这些被产业淘汰的从业人员的重要性，因此让社会很动荡。如今，各国政府意识到社会稳定很重要，因此即使很多人并不创造价值，也只好“养着”。为此，有些国家将无所事事的人强制塞到公司里（比如日本和欧盟），有些国家不肯淘汰过剩产能（比如中国），但解决问题的途径都是一个“耗”字。耗上两代，社会问题就解决了。

为什么每一次重大的技术革命都需要很长的时间来消除它所带来的负面影响呢？因为技术革命会使得很多产业消失，或者产业从业人口大量减少，释放出来的劳动力需要寻找出路。这个时间有多长呢？事实证明至少要一代人以上，因为我们必须承认一个并不愿意承认的事实，那就是被淘汰的产业的从业人员能够进入新行业中的其实非常少。 
虽然各国政府都试图通过各种手段帮助那些从业人员掌握新的技能，但是收效甚微，因为上一代人很难适应下一代的技术发展。事实上，消化这些劳动力主要靠的是等待他们逐渐退出劳务市场，而并非他们真正有了新的出路，能够和以前一样称心如意地工作。这就是每次技术革命都需要花半个世纪来消除它带来的动荡的原因。

在美国将近一半的人是不上税甚至从政府拿补贴的，从单纯经济的角度看，他们每天所提供的劳动仅仅是让自己生存下去而已，甚至还不够，他们对社会继续发展的贡献可以说是微乎其微。在一个民主国家，这些人最大的用途就是手中的那一张选票，以至于政客们为了选票可以轻易许诺，然后把国家的债务和赤字越堆越高。

社会公平只能反映在机会平等上，而不是结果的公平。

如果没有占领华尔街的人所反对的这2%的人，美国早就成了三流国家，甚至混得比希腊还惨。

大量低收入者或者无收入者的人出路在哪里？通过福利和救济将他们养起来，显然是不够的，因为那些人的人生前景依然是灰暗的。2016年，美国总统候选人特朗普替这些人说出了他们的希望——体面的工作

我们要在观念上接受这样一个事实，即越来越多的事情人类将做不过机器

在历次技术革命中，一个人、一家企业，甚至一个国家，可以选择的道路只有两条：要么进入前2%的行列，要么被淘汰。抱怨是没有用的。至于当下怎么才能成为这2%，其实很简单，就是踏上只能革命的浪潮。

针对2010年的占领华尔街运动以及2015年年底以来法国、 德国和比利时外来移民不断滋事的状况，大家在思考一个根本性的问题：这些不满情绪的根源在哪里？这不能简单地归结为贫富悬殊，或者宗教纷争。其根源在于，很多人被社会进步所抛弃了。 随着技术革命的发展，并非每一个人的发展机会都是越来越多的，反而可能是越来越少。 
是否能有良好的解决方法？坦率地讲，谁也没有。但是，即便没有好的解决方法，我们也要在观念上接受这样一个事实，即越来越多的事情人类将做不过机器。我们今后的决定，应该根据这个前提来做，只有面对现实，才能最终建设一个让所有积极向上的人都具有成就感和幸福感的社会。
虽然我们不知道如何在短期内创造出能消化几十亿劳动力的 产业，但是我们很清楚如何让自己在智能革命中受益，而不是被抛弃。这个答案很筒单，就是争当2%的人，而不是自豪地宣称自己是98%的人。

在历次技术革命中，一个人、一家企业，甚至一个国家，可以选择的道路只有两条：要么进入前2%的行列，要么被淘汰。抱怨是没有用的。至于当下怎么才能成为这2%，其实很简单，就是踏上智能革命的浪潮。

问：未来的时代是人的时代，还是机器的时代？我们是否会被机器控制？我的回答是：未来依然是人的时代，我们不会被机器控制，机器在完成任务时甚至不知道自己在做什么。比如Google AlphaGo, 其实并不知道自己是在下棋。但是，制造智能机器地人就不同了，他们可能只占人口的不到2%甚至更少，却在某种程度上控制着世界。 
这个说法不是危言資听，实际上今天已经发生了。大家不妨想想自己每天有多少时间挂在微信上，有多少商品是从淘宝或者京东购买的，有多少次出行是靠滴滴打车。这些公司没改变一点产品的形态，亿万用户的生活就被它们所左右了。更重要的是这些公司完全掌握了我们衣食住行的生活细节，它们可能比我们更了解我们自己。既然做到了对我们如此精确的把控，他们挣我们的钱便是不言而喻的事情。在销售商品的时代，我们认为越便宜越合算；到了提供服务的时代，我们发现忽然有了很多免费的服务，我们为此欢呼，但是不久我们会发现，看似免费的东西才是最贵的，因为我们在获得这些服务的同时交出了自己的自由。而只有当我们在失去自由，利益受到损失时，才会体会到自由的可贵。

在销售商品的时代，我们认为越便宜越合算；到了提供服务的时代，我们发现忽然有了很多免费的服务，我们为此欢呼，但是不久我们会发现，看似免费的东西才是最贵的，因为我们再获得这些服务的同时交出了自己的自由。

大数据导致机器革命的到来，这对未来社会的影响不仅仅存在于经济领域，而是全方位的。尽管总体上这些影响是正面的，从长远看会使我们未来的社会变得更好；不过，和以往的技术革命一样，智能革命也会带来很多负面的影响，特别是在它发展的初期，而这些影响可能会持续很久。 
任何一次技术革命，最初受益的都是发展它、使用它的人，而远离它、拒绝接受它的人，在很长的时间里都将是迷茫的一代。 在智能革命到来之际，作为人和企业无疑应该拥抱它，让自己成为那2%的受益者；而作为国家，则需要未雨调缕，争取不要像过去那祥每一次重大的技术革命都伴随半个多世纪的动汤。 
我们还没有经历过机器在智能上全面超越人类的时代，我们需要在这样的环境里学会生存。这将是一个让我们振奋的时代， 也是一个给我们带来空前挑战的时代。

大数据导致机器革命的到来，这对未来社会的影响不仅仅存在于经济领域，而是全方位的。尽管总体上这些影响是正面的，从长远看会使我们未来的社会变得更好;不过，和以往的技术革命一样，智能革命也会带来很多负面的影响，特别是在它发展的初期，而这些影响可能会持续很久。
    任何一次技术革命，最初受益的都是发展它、使用它的人，而远离它、拒绝接接受它的人，在很长的时间里都将是迷茫的一代在智能革命到来之际，作为人和企业无疑应该拥抱它，让自己成为那2%的受益者;而作为国家，则需要未雨绸缪，争取不要像过去那样每一次重大的技术革命都伴随半个多世纪的动荡。
    我们还没有经历过机器在智能上全面超越人类的时代，我们需要在这样的环境里学会生存。这将是一个让我们振奋的时代也是一个给我们带来空前挑战的时代。

